# acpl/configs/task/robust.yaml
# =============================================================================
# ACPL — Task config: ROBUST TRANSPORT under disorder
#
# Objective:
#   Maximize robust terminal success at target j*, under stochastic disorder ξ.
#   Supports expectation and CVaR risk sensitivity.
#
# IMPORTANT (current repo tooling):
# - scripts/gen_manifest.py does NOT support multi-family experiments yet.
#   Therefore, this task config defaults to a single family: ["line"].
# - Grid robust transport is supported by configuration blocks below, but should be
#   run from a dedicated experiment manifest (robust-grid-disorder.yaml) and with
#   explicit manifest generation per family.
# =============================================================================

task:
  name: robust
  objective: "maximize robust success at target j*"
  horizon_T: 128
  normalized_time_feature: true

data:
  # Default to single family for manifest/eval compatibility.
  family: ["line"]                       # override to ["grid-2d"] in a grid-only experiment

  # --------------------------- line family --------------------------- #
  line:
    N_min: 128
    N_max: 512
    # Source/target schemes interpreted by your dataset loader
    source: "left"                       # left | center | custom_index
    target: "right"                      # right | custom_index
    # Optional: allow excluding very small lines if instability occurs
    min_separation: 0                    # optional; if supported by loader

  # --------------------------- grid family (optional) ---------------- #
  grid:
    L_min: 48
    L_max: 96
    boundary: "open"
    source: "corner"                     # corner | center | custom_index
    target: "opposite-corner"

  # --------------------------- features ------------------------------ #
  features:
    include_degree: true
    laplacian_pe:
      enabled: true
      k: 8
      sign_fix: "max-abs-positive"
    coords:
      enabled_on_grids: true
      normalize: true

  batching:
    episodes_per_graph: 1
    graphs_per_batch: 2
    shuffle: true
    seed: 1447

# -----------------------------------------------------------------------------
# Disorder model ξ (train-time defaults; eval sweeps override these)
# -----------------------------------------------------------------------------
disorder:
  # Static edge phases φ_uv ~ N(0, σ^2), wrapped to (-π, π], sampled once per episode
  edge_phase:
    enabled: true
    sigma: 0.15                          # train-time default; eval sweeps override
    wrap: true
    # How many disorder draws per (graph, episode) item in training batches.
    # >1 increases robustness but increases compute/variance coupling.
    trials_per_episode: 1

  # Optional coin dephasing (e.g., random Z-rot on SU(2) head or diagonal noise on U(d))
  coin_dephase:
    enabled: false
    sigma: 0.0

  # Optional per-step edge dropout to simulate faults
  edge_dropout:
    enabled: false
    p: 0.0

# -----------------------------------------------------------------------------
# Robust loss: expectation and/or CVaR over disorder
# -----------------------------------------------------------------------------
loss:
  # robust_combo: combines expectation and CVaR (if cvar_alpha > 0) over disorder trials.
  # Typical: L = -Eξ[P_T(target; ξ)]  and optionally add CVaR term for risk sensitivity.
  kind: "robust_combo"

  # target_from_batch=true means the loader should provide batch['target_index'].
  # Otherwise, target may be derived from the data.* source/target scheme.
  target_from_batch: true

  # CVaR risk sensitivity; set 0 to disable CVaR and use pure expectation.
  cvar_alpha: 0.1

  # Monte Carlo for training: additional independent episodes per batch element.
  # This is separate from trials_per_episode (which is trials of disorder for same episode).
  monte_carlo:
    episodes: 2                          # trade-off compute vs gradient variance

  reduction: "mean"
  clamp_min_p: 1.0e-9                    # numerical floor

# -----------------------------------------------------------------------------
# Regularization on θ(v,t) schedules (Phase B5)
# -----------------------------------------------------------------------------
regularization:
  smooth_theta: 2.5e-3                   # temporal smoothness of coin parameters
  l2_theta: 1.0e-4                       # magnitude penalty

  spectral:
    enabled: true
    dct_weight: 1.0e-4
    hf_bins: 0.5

  grad_clip_norm: 1.5

# -----------------------------------------------------------------------------
# Training loop configuration
# -----------------------------------------------------------------------------
training:
  # Robust is still differentiable here -> backprop by default.
  # Switch to PPO if you introduce non-differentiable reward callbacks.
  method: "backprop"                     # backprop | ppo

  optimizer:
    name: "adamw"
    lr: 1.5e-4
    betas: [0.9, 0.999]
    weight_decay: 2.0e-4
    eps: 1.0e-8

  scheduler:
    enabled: true
    # runner may interpret "cosine" as cosine_warmup or cosine; match your loop logic
    name: "cosine_warmup"
    warmup_steps: 500

  epochs: 100
  steps_per_epoch: 400
  accum_steps: 1
  amp: true
  device: "cuda"

  log_every: 50
  log_grad_norm_every: 200

  ckpt:
    dir: "checkpoints/robust"
    keep_last: 6
    save_every_steps: 2000
    save_best_metric: "eval/target/success"  # higher is better (success)

# -----------------------------------------------------------------------------
# PPO (disabled unless training.method switched)
# -----------------------------------------------------------------------------
ppo:
  enabled: false
  rollout_length: 128
  epochs: 4
  minibatch_size: 2048
  clip_eps: 0.2
  vf_coef: 0.5
  ent_coef: 0.01
  gamma: 0.995
  gae_lambda: 0.95
  max_grad_norm: 1.0

# -----------------------------------------------------------------------------
# Evaluation defaults (CI-style evaluation should use frozen manifests)
# -----------------------------------------------------------------------------
eval:
  seeds: [551, 552, 553, 651, 652]
  ci_alpha: 0.1
  metrics:
    - "target/success"
    - "target/maxp"                      # optional if supported
    - "mix/tv"
    - "mix/H"

  robustness:
    enabled: true
    edge_phase:
      sigma_grid: [0.0, 0.05, 0.1, 0.15, 0.2]
      trials: 8

    coin_dephase:
      sigma_grid: [0.0, 0.05, 0.1]
      trials: 6

viz:
  pt_timelines:
    enabled: true
    topk_vertices: 8

  tv_curves:
    enabled: true

  spectra:
    enabled: true
    dct_show_bins: 24
